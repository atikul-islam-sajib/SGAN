{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import zipfile\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    with open(\"../../config.yml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(value = None, filename = None):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Value or filename is not found\".capitalize())\n",
    "    \n",
    "def load(filename = None):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename=filename)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Filename is not found\".capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader():\n",
    "    def __init__(self, image_path = None, image_size = 64, batch_size = 4, split_size = 0.50):\n",
    "        self.image_path = image_path\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.split_size = split_size\n",
    "\n",
    "        self.config = config()\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "    def split_images(self, **kwargs):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            kwargs[\"X\"], kwargs[\"y\"], test_size=self.split_size, random_state=42)\n",
    "\n",
    "        return {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test}\n",
    "\n",
    "    def transforms(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, ], std=[0.5, ])\n",
    "        ])\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        if os.path.exists(self.config[\"path\"][\"raw_path\"]):\n",
    "\n",
    "            with zipfile.ZipFile(self.image_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(self.config[\"path\"][\"raw_path\"])\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Raw path is not found for the directory\".capitalize())\n",
    "\n",
    "    def extract_feature(self):\n",
    "\n",
    "        self.directory = os.path.join(self.config[\"path\"][\"raw_path\"], \"brain\")\n",
    "        self.categories = [file for file in os.listdir(self.directory)]\n",
    "\n",
    "        for category in self.categories: \n",
    "            full_path = os.path.join(self.directory, category)\n",
    "\n",
    "            for image in os.listdir(full_path): \n",
    "                full_image_path = os.path.join(full_path, image)\n",
    "\n",
    "                image_object = Image.fromarray(cv2.imread(full_image_path))\n",
    "                self.images.append(self.transforms()(image_object))\n",
    "                self.labels.append(self.categories.index(category))\n",
    "\n",
    "        dataset = self.split_images(X = self.images, y = self.labels)\n",
    "\n",
    "        X_limit = round(len(dataset[\"X_train\"]) * 1.0)\n",
    "        y_limit = round(len(dataset[\"y_train\"]) * 1.0)\n",
    "\n",
    "        sub_dataset = self.split_images(\n",
    "            X = dataset[\"X_train\"][0:X_limit], y = dataset[\"y_train\"][0:y_limit])\n",
    "\n",
    "        return {\n",
    "            \"X_train\": sub_dataset[\"X_train\"],\n",
    "            \"y_train\": sub_dataset[\"y_train\"],\n",
    "            \"X_test\": sub_dataset[\"X_test\"],\n",
    "            \"y_test\": sub_dataset[\"y_test\"],\n",
    "            \"val_train\": dataset[\"X_test\"],\n",
    "            \"val_test\": dataset[\"y_test\"]\n",
    "            }\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        dataset = self.extract_feature()\n",
    "\n",
    "        self.train_dataloader = DataLoader(\n",
    "            dataset=list(zip(dataset[\"X_train\"], dataset[\"y_train\"])), batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "        self.test_dataloader = DataLoader(\n",
    "            dataset=list(zip(dataset[\"X_test\"], dataset[\"y_test\"])), batch_size=self.batch_size*4, shuffle=True\n",
    "        )\n",
    "\n",
    "        self.val_dataloader = DataLoader(\n",
    "            dataset=list(zip(dataset[\"val_train\"], dataset[\"val_test\"])), batch_size=self.batch_size, shuffle=True\n",
    "        )\n",
    "        if os.path.exists(self.config[\"path\"][\"processed_path\"]):\n",
    "\n",
    "            dump(\n",
    "                value=self.train_dataloader,\n",
    "                filename=os.path.join(\n",
    "                    self.config[\"path\"][\"processed_path\"], \"train_dataloader.pkl\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            dump(\n",
    "                value=self.test_dataloader,\n",
    "                filename=os.path.join(\n",
    "                    self.config[\"path\"][\"processed_path\"], \"test_dataloader.pkl\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            dump(\n",
    "                value=self.val_dataloader,\n",
    "                filename=os.path.join(\n",
    "                    self.config[\"path\"][\"processed_path\"], \"val_dataloader.pkl\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Processed path is not found for the directory\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def dataset_details():\n",
    "        config_files = config()\n",
    "\n",
    "        if os.path.exists(config_files[\"path\"][\"processed_path\"]):\n",
    "\n",
    "            train_dataloader = load(\n",
    "                filename=os.path.join(\n",
    "                    config_files[\"path\"][\"processed_path\"], \"train_dataloader.pkl\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            test_dataloader = load(\n",
    "                filename=os.path.join(\n",
    "                    config_files[\"path\"][\"processed_path\"], \"test_dataloader.pkl\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            val_dataloader = load(\n",
    "                filename=os.path.join(\n",
    "                    config_files[\"path\"][\"processed_path\"], \"val_dataloader.pkl\"\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"total_data(Train)\": sum(\n",
    "                        data.size(0) for data, _ in train_dataloader\n",
    "                    ),\n",
    "                    \"total_data(Test)\": sum(\n",
    "                        data.size(0) for data, _ in test_dataloader\n",
    "                    ),\n",
    "                    \"total_data(Val)\": sum(data.size(0) for data, _ in val_dataloader),\n",
    "                    \"total_batch(Train)\": str(len(train_dataloader)),\n",
    "                    \"total_batch(Test)\": str(len(test_dataloader)),\n",
    "                    \"total_data\": sum(\n",
    "                        [\n",
    "                            sum([data.size(0) for data, _ in dataloader])\n",
    "                            for dataloader in [\n",
    "                                train_dataloader,\n",
    "                                test_dataloader,\n",
    "                                val_dataloader,\n",
    "                            ]\n",
    "                        ]\n",
    "                    ),\n",
    "                    \"train_shape\": str(\n",
    "                        [data.size() for _, (data, _) in enumerate(train_dataloader)][0]\n",
    "                    ),\n",
    "                    \"test_shape\": str(\n",
    "                        [data.size() for _, (data, _) in enumerate(test_dataloader)][0]\n",
    "                    ),\n",
    "                    \"val_shape\": str(\n",
    "                        [data.size() for _, (data, _) in enumerate(val_dataloader)][0]\n",
    "                    ),\n",
    "                },\n",
    "                index=[\"quantity\"],\n",
    "            ).to_csv(\n",
    "                os.path.join(config_files[\"path\"][\"files_path\"], \"dataset_details.csv\")\n",
    "                if os.path.exists(config_files[\"path\"][\"files_path\"])\n",
    "                else os.makedirs(config_files[\"path\"][\"files_path\"])\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Processed path is not found for the directory\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_images():\n",
    "        config_files = config()\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        if os.path.exists(config_files[\"path\"][\"processed_path\"]):\n",
    "            test_dataloader = load(filename=os.path.join(config_files[\"path\"][\"processed_path\"], \"test_dataloader.pkl\"))\n",
    "            \n",
    "            images, labels = next(iter(test_dataloader))\n",
    "            \n",
    "            for index, image in enumerate(images):\n",
    "                image = image.squeeze().permute(1, 2, 0).cpu().detach().numpy()\n",
    "                image = (image - image.min())/(image.max() - image.min())\n",
    "                \n",
    "                plt.subplot(4, 4, index + 1)\n",
    "                \n",
    "                plt.imshow(image, cmap=\"gray\")\n",
    "                plt.title(\"Yes\" if labels[index] == 0 else \"No\")\n",
    "                plt.axis(\"off\")\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(os.path.join(config_files[\"path\"][\"files_path\"], \"images.png\")) \\\n",
    "                if os.path.exists(config_files[\"path\"][\"files_path\"]) else \"Cannot save the images to\".capitalize()\n",
    "            plt.show()\n",
    "        \n",
    "        else:\n",
    "            raise FileNotFoundError(\"Processed path is not found for the directory\".capitalize())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(image_path=\"/Users/shahmuhammadraditrahman/Desktop/tumor.zip\")\n",
    "    loader.unzip_folder()\n",
    "    loader.create_dataloader()\n",
    "    loader.dataset_details()\n",
    "    loader.plot_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
